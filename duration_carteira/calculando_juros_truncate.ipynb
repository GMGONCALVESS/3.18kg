{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9c338b-3e0b-487b-bfb4-f1006d080ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import xlrd\n",
    "import requests\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, MetaData, Table\n",
    "from datetime import datetime, date, timedelta\n",
    "from urllib.request import urlretrieve\n",
    "from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from openpyxl import Workbook\n",
    "\n",
    "\n",
    "def get_curva_cdi(periodo):\n",
    "    curva_di = pd.read_excel(\"curvadi_1902.xlsx\")\n",
    "\n",
    "    x1 = curva_di.loc[curva_di['tenor'] >= periodo, 'bid_yield'].min()\n",
    "    y1 = curva_di.loc[curva_di['bid_yield'] == x1, 'tenor'].values[0] if pd.notna(x1) else None\n",
    "\n",
    "    x2 = curva_di.loc[curva_di['tenor'] > periodo, 'bid_yield'].min()\n",
    "    y2 = curva_di.loc[curva_di['bid_yield'] == x2, 'tenor'].values[0] if pd.notna(x2) else None\n",
    "    m = (y2-y1)/(x2-x1)\n",
    "    b = y1-m*x1\n",
    "    # part1 = (1 + y1 / 100)\n",
    "    # part2 = (1 + y2 / 100) / (1 + y1 / 100)\n",
    "    # exponent = (periodo - x1) / (x2 - x1)\n",
    "\n",
    "    # result = ((part1 * (part2 ** exponent)) - 1) * 100\n",
    "\n",
    "    # Interpolando exponencialmente\n",
    "    print(f'x1:{x1}, x2:{x2},y1:{y1}, y2:{y2}, m:{m}')\n",
    "\n",
    "    print(type(x1), type(x2), type(y1), type(y2))\n",
    "\n",
    "    return m*periodo + b\n",
    "    # return result\n",
    "    \n",
    "\n",
    "def calcula_termo_di_spread(exp, exp_i, du, du_i, S):\n",
    "    termo = ((((exp/100+1)**(1/252))*((S/100 + 1)**(1/252)))**du)/((((exp_i/100+1)**(1/252))*((S/100 + 1)**(1/252)))**du_i)\n",
    "    return termo\n",
    "\n",
    "\n",
    "def truncate(value, decimals=16):\n",
    "    factor = 10 ** decimals\n",
    "    return np.trunc(value * factor) / factor\n",
    "\n",
    "# Pega feriados nacionais pelo calendário da Anbima\n",
    "def holidays(url=None, path=None):\n",
    "    if not url:\n",
    "        url = 'http://www.anbima.com.br/feriados/arqs/feriados_nacionais.xls'\n",
    "    if not path:\n",
    "        path = 'feriados_nacionais.xls'\n",
    "    try:\n",
    "        wb = xlrd.open_workbook(path)\n",
    "    except:\n",
    "        response = urlretrieve(url, filename=path)\n",
    "        wb = xlrd.open_workbook(path)\n",
    "    ws = wb.sheet_by_index(0)\n",
    "    i = 1\n",
    "    dates = []\n",
    "    while ws.cell_type(i, 0) == 3:\n",
    "        y, m, d, _, _, _ = xlrd.xldate_as_tuple(\n",
    "            ws.cell_value(i, 0), wb.datemode)\n",
    "        dates.append(date(y, m, d))\n",
    "        i += 1\n",
    "    return dates\n",
    "\n",
    "# Cria calendário de feriados nacionais\n",
    "class CustomBusinessCalendar(AbstractHolidayCalendar):\n",
    "    rules = [Holiday('Brazil Holiday', month=date.month,\n",
    "                     day=date.day, year=date.year) for date in holidays()]\n",
    "\n",
    "\n",
    "def get_busdays(start_date, end_date):\n",
    "    # Cria calendário de dias úteis\n",
    "    custom_business_day = CustomBusinessDay(calendar=CustomBusinessCalendar())\n",
    "    dates = pd.bdate_range(start=start_date, end=end_date,\n",
    "                           freq=custom_business_day)\n",
    "    return len(dates)\n",
    "\n",
    "# Define the function to swap the rows\n",
    "\n",
    "\n",
    "def swap_rows(df):\n",
    "    # Iterate over the DataFrame by index\n",
    "    i = 0\n",
    "    while i < len(df) - 1:\n",
    "        # Check if the 'evento' column has the specific values in the current row\n",
    "        if df.at[i, 'evento'] in ['Amortizacao', 'Vencimento (resgate)']:\n",
    "            # Swap the current row with the next one\n",
    "            df.iloc[i], df.iloc[i+1] = df.iloc[i+1].copy(), df.iloc[i].copy()\n",
    "            # Move the index by 2 to skip the next row (since it's already swapped)\n",
    "            i += 1\n",
    "        i += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def adjust_pu(row, previous_pu):\n",
    "    if row['evento'] in ['Amortizacao', 'Vencimento (resgate)', 'Resgate total antecipado']:\n",
    "        if row['codigo_ticker'] == 'SNGO18' and row['evento'] == 'Amortizacao':\n",
    "            # print(f'percentual_taxa:{row['percentual_taxa']}; vne:{row['vne']}')\n",
    "            valor_pago = (row['percentual_taxa']/100.0) * row['vne']\n",
    "            return previous_pu - valor_pago\n",
    "        else:\n",
    "            # Adjust using the previous 'pu'\n",
    "            return previous_pu * (1 - row['percentual_taxa'] / 100)\n",
    "       # return previous_pu * (1 - row['percentual_taxa'] / 100)  # Adjust using the previous 'pu'\n",
    "    else:\n",
    "        return previous_pu  # Use the previous 'pu' for other events without adjustment\n",
    "\n",
    "# Step 1: Create a function to find the closest tenor\n",
    "\n",
    "\n",
    "def get_closest_tenor(days, tenores_dict):\n",
    "    # Find the tenor with the minimum difference to 'days'\n",
    "    closest_tenor = min(tenores_dict, key=lambda k: abs(k - days))\n",
    "    return closest_tenor\n",
    "\n",
    "\n",
    "def calcular_juros_acimadi(vne, spread_anual, dp, start_date, end_date):\n",
    "    # Constante: 252 dias úteis no ano\n",
    "    dias_uteis_ano = 252\n",
    "\n",
    "    vne = truncate(vne, 6)\n",
    "\n",
    "    \n",
    "    tdi_k_diario = pd.DataFrame()\n",
    "\n",
    "    # Seleciona o período do DI\n",
    "    tdi_k_diario = indicador_cdi[(indicador_cdi['index'] >= start_date) & (\n",
    "        indicador_cdi['index'] < end_date)]\n",
    "\n",
    "    tdi_k_diario.to_excel('tdi_k_diario.xlsx')\n",
    "\n",
    "    # Calcular a taxa DI diária\n",
    "    tdi_k_diario.loc[:, 'tdi_k_diario'] = truncate((\n",
    "        (1 + tdi_k_diario['px_last']/100) ** (1/dias_uteis_ano) - 1), 16)\n",
    "    # tdi_k_diario.loc[:, 'tdi_k_diario'] = tdi_k_diario['tdi_k_diario'] + 1\n",
    "\n",
    "    #tdi_k_diario.loc[:, 'tdi_k_diario'] = truncate(tdi_k_diario[:, 'tdi_k_diario'], 16)\n",
    "    \n",
    "    # Calcular o fator DI\n",
    "    spread_anual = round(spread_anual, 2)\n",
    "    fator_di = np.prod(1 + (tdi_k_diario['tdi_k_diario'] * (spread_anual/100)))\n",
    "\n",
    "    fator_di = round(fator_di, 8)\n",
    "    \n",
    "    # Calcular os juros\n",
    "    #se for o primeiro pagamento\n",
    "    juros = vne * (fator_di - 1)\n",
    "\n",
    "    print({\n",
    "        'Fator DI': fator_di,\n",
    "        'Juros Pagos': juros\n",
    "    })\n",
    "\n",
    "    return juros\n",
    "\n",
    "\n",
    "def calcular_juros(vne, spread_anual, dp, start_date, end_date, linha, ordem):\n",
    "    data_atual = '2025-02-20'\n",
    "    #DI spread\n",
    "    # Constante: 252 dias úteis no ano\n",
    "    dias_uteis_ano = 252\n",
    "\n",
    "    vne = truncate(vne, 6)\n",
    "    \n",
    "    tdi_k_diario = pd.DataFrame()\n",
    "\n",
    "    # Seleciona o período do DI\n",
    "    tdi_k_diario = indicador_cdi[(indicador_cdi['index'] >= start_date) & (\n",
    "        indicador_cdi['index'] < end_date)]\n",
    "\n",
    "    tdi_k_diario.to_excel('tdi_k_diario.xlsx')\n",
    "\n",
    "    # Calcular a taxa DI diária\n",
    "    tdi_k_diario.loc[:, 'tdi_k_diario'] = truncate((\n",
    "        1 + tdi_k_diario['px_last']/100) ** (1/dias_uteis_ano) - 1, 16)\n",
    "    tdi_k_diario.loc[:, 'tdi_k_diario'] = tdi_k_diario['tdi_k_diario'] + 1\n",
    "    #### POSSIVELMENTE MODIFICAR O PARENTESIS\n",
    "    #tdi_k_diario = truncate(tdi_k_diario, 16)\n",
    "    \n",
    "    # Calcular o fator DI\n",
    "    fator_di = np.prod(tdi_k_diario['tdi_k_diario'])\n",
    "    spread_anual = round(spread_anual, 4)\n",
    "    \n",
    "    fator_di = round(fator_di, 8)\n",
    "\n",
    "    du = get_busdays(data_atual, end_date)\n",
    "    \n",
    "    # Calcular o fator spread\n",
    "    fator_spread = (1 + spread_anual / 100) ** (du / dias_uteis_ano)\n",
    "    \n",
    "    # Calcular o fator de juros\n",
    "    fator_juros = fator_di * fator_spread\n",
    "\n",
    "    fator_juros = round(fator_juros, 9)\n",
    "\n",
    "    exp = get_curva_cdi(du) #MODIFICAR PARA DIAS UTEIS\n",
    "    if ordem != 1:\n",
    "        indice_dpi = linha['deb_id']-1\n",
    "        print(f'indice_i: {indice_dpi}')\n",
    "        end_i = eventos_debenture_cdi.loc[eventos_debenture_cdi[\"deb_id\"] == indice_dpi, 'end_date']\n",
    "        print(f'end_i: {end_i}')\n",
    "        du_i = get_busdays(data_atual, end_i)\n",
    "        print(f'du_i: {du_i}')\n",
    "        exp_i = get_curva_cdi(du_i)\n",
    "    # O PROBLEMA É COMO CONSEGUIR O DPI\n",
    "\n",
    "    fator_multiplicativo = (((exp/100 + 1)**(1/252))*((spread_anual/100 + 1)**(1/252)))**(du)\n",
    "    \n",
    "    # Calcular os juros\n",
    "    #se for o primeiro pagamento\n",
    "    if ordem == 1:\n",
    "        juros = vne*(fator_juros*fator_multiplicativo - 1) #vne * (fator_juros - 1)\n",
    "    else:\n",
    "        termo = calcula_termo_di_spread(exp, exp_i, du, du_i, spread_anual)\n",
    "        juros = vne*termo\n",
    "    #se for o segundo pagamento\n",
    "    \n",
    "    print({\n",
    "        'Fator DI': fator_di,\n",
    "        'Fator Spread': fator_spread,\n",
    "        'Fator Juros': fator_juros,\n",
    "        'Juros Pagos': juros\n",
    "    })\n",
    "\n",
    "    return juros\n",
    "\n",
    "# Function to calculate juros_pagos only for 'Pagamento de Juros' events\n",
    "\n",
    "\n",
    "def apply_calcular_juros(row):\n",
    "    if row['inicio_rentabilidade'] == row['start_date']:\n",
    "        ordem = 1\n",
    "    else:\n",
    "        ordem = 2\n",
    "        \n",
    "    if (row['evento'] == 'Pagamento de juros'):\n",
    "        # Call the calcular_juros function using the appropriate columns\n",
    "        dp = row['dp'] - 1\n",
    "        print(f'evento:{row['evento']}; vne:{row['pu']}; percentual_taxa:{row['percentual_taxa']}; dp:{dp}; start_date:{row['start_date']}; end_date:{row['end_date']}')\n",
    "        if row['percentual_taxa'] >= 100:\n",
    "            return calcular_juros_acimadi(row['pu'], row['percentual_taxa'], dp, row['start_date'], row['end_date'])\n",
    "        else:\n",
    "            return calcular_juros(row['pu'], row['percentual_taxa'], dp, row['start_date'], row['end_date'], row, ordem)\n",
    "    elif row['evento'] in ['Amortizacao', 'Vencimento (resgate)', 'Resgate total antecipado']:\n",
    "        print(f'evento: {row['evento']}; pu:{row['pu']}')\n",
    "        return row['pu']\n",
    "    return None  # Return None for rows that don't match the condition\n",
    "\n",
    "\n",
    "def update_valor_recebido(row, previous_row):\n",
    "    # Check if the event is 'Resgate total antecipado' or 'Vencimento (resgate)'\n",
    "    if row['evento'] in ['Resgate total antecipado', 'Vencimento (resgate)']:\n",
    "        # Get the previous row's 'pu' and multiply by 'quantidade'\n",
    "        return previous_row['pu'] * row['quantidade'] if pd.notnull(previous_row['pu']) else None\n",
    "    # Return the original valor_recebido for other rows\n",
    "    return row['valor_recebido']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d8515c-ba50-47df-adba-f445a6503cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = eventos_debenture_cdi['juros_pagos'].isna()\n",
    "#if row.name == eventos_debenture_cdi[mask].index[0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed2297-96c3-44bf-90b4-4594c60bda23",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos_debenture_cdi.iloc[30:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca6f18-d8fd-4d6a-8228-4cf00d606009",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos_debenture_cdi[mask].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d789de-4dea-4085-806e-64f48bfa958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 'postgresql://username:password@localhost:5432/your_database'\n",
    "engine = create_engine(\n",
    "    'postgresql://postgres:admin@192.168.88.61:5432/posicoesdb')\n",
    "\n",
    "# sql query to read all the records\n",
    "posicoes_query = pd.read_sql(\n",
    "    'SELECT * FROM posicoes_pbi ORDER BY posicao_id', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "posicoes_pbi = pd.DataFrame(posicoes_query)\n",
    "\n",
    "# sql query to read all the records\n",
    "eventos_query = pd.read_sql(\n",
    "    'SELECT * FROM eventos_debenture ORDER BY deb_id', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "eventos_debenture = pd.DataFrame(eventos_query)\n",
    "\n",
    "# sql query to read all the records\n",
    "eventos_cricra_query = pd.read_sql(\n",
    "    'SELECT * FROM eventos_cricra ORDER BY cricra_id', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "eventos_cricra = pd.DataFrame(eventos_cricra_query)\n",
    "\n",
    "# sql query to read all the records\n",
    "curvadi_query = pd.read_sql('SELECT * FROM curva_di ORDER BY di_index', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "curva_di = pd.DataFrame(curvadi_query)\n",
    "curva_di = pd.read_excel(\"curvadi_1902.xlsx\")\n",
    "\n",
    "\n",
    "start_date = '2019-02-26'\n",
    "end_date = '2050-08-26'\n",
    "\n",
    "# Cria calendário de dias úteis\n",
    "custom_business_day = CustomBusinessDay(calendar=CustomBusinessCalendar())\n",
    "dates = pd.bdate_range(start=start_date, end=end_date,\n",
    "                       freq=custom_business_day)\n",
    "\n",
    "eventos_debenture_cdi = eventos_debenture[eventos_debenture['indice'] == 'DI']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03d5afb-6860-4ce5-8456-32d38e6d9f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deb_id</th>\n",
       "      <th>data_evento</th>\n",
       "      <th>data_liquidacao</th>\n",
       "      <th>evento</th>\n",
       "      <th>percentual_taxa</th>\n",
       "      <th>valor_pago</th>\n",
       "      <th>status</th>\n",
       "      <th>codigo_ticker</th>\n",
       "      <th>vne</th>\n",
       "      <th>remuneracao</th>\n",
       "      <th>inicio_rentabilidade</th>\n",
       "      <th>indice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>Pagamento de juros</td>\n",
       "      <td>1.3</td>\n",
       "      <td>72.374922</td>\n",
       "      <td>Liquidado</td>\n",
       "      <td>BSA316</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>DI + 1,3000%</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>2023-08-07</td>\n",
       "      <td>Pagamento de juros</td>\n",
       "      <td>1.3</td>\n",
       "      <td>71.738112</td>\n",
       "      <td>Liquidado</td>\n",
       "      <td>BSA316</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>DI + 1,3000%</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>2024-02-05</td>\n",
       "      <td>2024-02-05</td>\n",
       "      <td>Pagamento de juros</td>\n",
       "      <td>1.3</td>\n",
       "      <td>65.838365</td>\n",
       "      <td>Liquidado</td>\n",
       "      <td>BSA316</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>DI + 1,3000%</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>2024-05-29</td>\n",
       "      <td>Resgate total antecipado</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Liquidado</td>\n",
       "      <td>BSA316</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>DI + 1,3000%</td>\n",
       "      <td>2022-08-09</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>Pagamento de juros</td>\n",
       "      <td>3.5</td>\n",
       "      <td>32.696236</td>\n",
       "      <td>Liquidado</td>\n",
       "      <td>JSMLA5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>DI + 3,5000%</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>DI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    deb_id data_evento data_liquidacao                    evento  \\\n",
       "42      42  2023-02-06      2023-02-06        Pagamento de juros   \n",
       "43      43  2023-08-07      2023-08-07        Pagamento de juros   \n",
       "44      44  2024-02-05      2024-02-05        Pagamento de juros   \n",
       "45      45  2024-05-29      2024-05-29  Resgate total antecipado   \n",
       "62      62  2022-01-17      2022-01-17        Pagamento de juros   \n",
       "\n",
       "    percentual_taxa  valor_pago     status codigo_ticker     vne  \\\n",
       "42              1.3   72.374922  Liquidado        BSA316  1000.0   \n",
       "43              1.3   71.738112  Liquidado        BSA316  1000.0   \n",
       "44              1.3   65.838365  Liquidado        BSA316  1000.0   \n",
       "45              0.0    0.000000  Liquidado        BSA316  1000.0   \n",
       "62              3.5   32.696236  Liquidado        JSMLA5  1000.0   \n",
       "\n",
       "     remuneracao inicio_rentabilidade indice  \n",
       "42  DI + 1,3000%           2022-08-09     DI  \n",
       "43  DI + 1,3000%           2022-08-09     DI  \n",
       "44  DI + 1,3000%           2022-08-09     DI  \n",
       "45  DI + 1,3000%           2022-08-09     DI  \n",
       "62  DI + 3,5000%           2021-09-30     DI  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventos_debenture_cdi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2fec3-2462-4a06-b3b1-c341d678aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventos_debenture_cdi[eventos_debenture['codigo_ticker'] == 'ALGA28']\n",
    "eventos_debenture_cdi.reset_index(drop=True, inplace=True)\n",
    "eventos_debenture_cdi['deb_id'] = eventos_debenture_cdi.index\n",
    "\n",
    "# Apply the swap function\n",
    "eventos_debenture_cdi = swap_rows(eventos_debenture_cdi)\n",
    "\n",
    "# Update the 'percentual_taxa' column to 100 where 'evento' is 'Vencimento (resgate)' or 'Resgate total antecipado'\n",
    "eventos_debenture_cdi.loc[eventos_debenture_cdi['evento'].isin(\n",
    "    ['Vencimento (resgate)', 'Resgate total antecipado']), 'percentual_taxa'] = 100\n",
    "\n",
    "# eventos_debenture_cdi['pu'] = 1000.0\n",
    "eventos_debenture_cdi['pu'] = eventos_debenture_cdi['vne']\n",
    "# Adjust 'pu' using the previous 'pu' value for 'Amortizacao' or 'Vencimento (resgate)'\n",
    "\n",
    "previous_codigo = None\n",
    "previous_pu = None\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for index, row in eventos_debenture_cdi.iterrows():\n",
    "    if previous_codigo is not None and previous_codigo != row['codigo_ticker']:\n",
    "        # Set 'pu' to 1000.0 when a new 'codigo_ticker' is encountered\n",
    "        # eventos_debenture_cdi.at[index, 'pu'] = 1000.0\n",
    "        # previous_pu = 1000.0  # Reset previous_pu to 1000.0 for the new ticker\n",
    "        eventos_debenture_cdi.at[index, 'pu'] = row['vne']\n",
    "        # Reset previous_pu to 1000.0 for the new ticker\n",
    "        previous_pu = row['vne']\n",
    "    elif previous_pu is not None:\n",
    "        # Adjust or propagate the previous 'pu'\n",
    "        eventos_debenture_cdi.at[index, 'pu'] = adjust_pu(row, previous_pu)\n",
    "\n",
    "    # Update the previous values for 'codigo_ticker' and 'pu'\n",
    "    previous_codigo = row['codigo_ticker']\n",
    "    # Store the updated 'pu'\n",
    "    previous_pu = eventos_debenture_cdi.at[index, 'pu']\n",
    "\n",
    "\n",
    "indicador_brasil_usa_query = pd.read_sql(\n",
    "    \"SELECT * FROM indicadores_brasil_usa WHERE pais = 'Brasil' ORDER BY indicador_id\", engine)\n",
    "\n",
    "indicador_brasil = pd.DataFrame(indicador_brasil_usa_query)\n",
    "\n",
    "# sql query to read all the records\n",
    "indicadorcdi_query = pd.read_sql(\n",
    "    'SELECT * FROM indicador_cdi ORDER BY index', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "indicador_cdi = pd.DataFrame(indicadorcdi_query)\n",
    "\n",
    "\n",
    "# Step 1: Convert the date columns to datetime if necessary\n",
    "eventos_debenture_cdi['data_evento'] = pd.to_datetime(\n",
    "    eventos_debenture_cdi['data_evento'])\n",
    "indicador_cdi['index'] = pd.to_datetime(indicador_cdi['index'])\n",
    "indicador_brasil['data'] = pd.to_datetime(indicador_brasil['data'])\n",
    "\n",
    "# Step 2: Merge the DataFrames based on the date column\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.merge(\n",
    "    indicador_cdi[['index', 'px_last']],  # Select only the necessary columns\n",
    "    left_on='data_evento',  # Merge on the 'data_evento' column in eventos_debenture_cdi\n",
    "    right_on='index',  # Merge on the 'index' column in indicador_cdi\n",
    "    how='left'  # Keep all rows from eventos_debenture_cdi and match with indicador_cdi\n",
    ")\n",
    "\n",
    "# Step 3: Rename the 'px_last' column to 'cdi' and drop the redundant 'index' column\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.rename(\n",
    "    columns={'px_last': 'cdi'})\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.drop(columns=['index'])\n",
    "\n",
    "# Step 2: Merge the DataFrames based on the date column\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.merge(\n",
    "    indicador_brasil[['data', 'cdi']],  # Select only the necessary columns\n",
    "    left_on='data_evento',  # Merge on the 'data_evento' column in eventos_debenture_cdi\n",
    "    right_on='data',  # Merge on the 'index' column in indicador_cdi\n",
    "    how='left'  # Keep all rows from eventos_debenture_cdi and match with indicador_cdi\n",
    ")\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.rename(columns={'cdi_y': 'cdi'})\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.drop(columns=['data', 'cdi_x'])\n",
    "\n",
    "tenores = pd.read_excel('curvadi_1902.xlsx')\n",
    "\n",
    "tenores = tenores.set_index('tenor')['bid_yield'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e912fb4-3c2f-4ef4-a93e-16878db5dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_cdi['index'] = pd.to_datetime(indicador_cdi['index'])\n",
    "\n",
    "max_date = eventos_debenture_cdi['data_evento'].max()\n",
    "min_date = indicador_cdi['index'].max()\n",
    "\n",
    "custom_business_day = CustomBusinessDay(calendar=CustomBusinessCalendar())\n",
    "new_dates = pd.bdate_range(\n",
    "    start=min_date, end=max_date, freq=custom_business_day)\n",
    "new_dates = new_dates[1:]\n",
    "\n",
    "new_entries = pd.DataFrame({\n",
    "    'index': new_dates,\n",
    "    'px_last': [float('nan')] * len(new_dates)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142fa52-b4e6-46c9-8b0d-1769bd1a122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new entries to indicador_cdi\n",
    "indicador_cdi = pd.concat([indicador_cdi, new_entries], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by 'data' to maintain chronological order\n",
    "indicador_cdi.sort_values(by='index', inplace=True)\n",
    "\n",
    "# Reset index if necessary\n",
    "indicador_cdi.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28c0ead-4dad-412f-a85a-4979e6a1e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Set the max height and enable scrolling\n",
    "def display_scrollable(df, max_height=400, max_width=1000):\n",
    "    display(HTML(df.to_html(classes=\"scroll-table\")))\n",
    "\n",
    "    # Apply CSS to make it scrollable\n",
    "    display(HTML(f\"\"\"\n",
    "    <style>\n",
    "        .scroll-table {{\n",
    "            max-height: {max_height}px;\n",
    "            max-width: {max_width}px;\n",
    "            overflow: auto;\n",
    "            display: block;\n",
    "            white-space: nowrap;\n",
    "        }}\n",
    "    </style>\n",
    "    \"\"\"))\n",
    "\n",
    "# Example usage\n",
    "display_scrollable(indicador_cdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bc67d-eb2b-46e2-a972-c7a094a8d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_cdi['days'] = (indicador_cdi['index'] - datetime.today()).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc4cfb-ae1a-4e7b-9776-b74e50c6e56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_cdi['tenor'] = indicador_cdi['days'].apply(\n",
    "    lambda x: get_closest_tenor(x, tenores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacaa2c2-3226-4b5b-970f-343c3b0f0fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_cdi = indicador_cdi.merge(\n",
    "    curva_di[['tenor', 'bid_yield']], on='tenor', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016f333-5f9a-4b0c-95a5-a1126c3d8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicador_cdi['px_last'] = indicador_cdi['px_last'].fillna(\n",
    "    indicador_cdi['bid_yield'])\n",
    "indicador_cdi = indicador_cdi.drop(columns=['bid_yield'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c30238-5567-4fe0-a304-101856adf040",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos_debenture_cdi['days'] = (\n",
    "    eventos_debenture_cdi['data_evento'] - datetime.today()).dt.days\n",
    "\n",
    "# Step 2: Apply the function to create a new 'tenor' column\n",
    "eventos_debenture_cdi['tenor'] = eventos_debenture_cdi['days'].apply(\n",
    "    lambda x: get_closest_tenor(x, tenores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3e758-f16d-45f8-8879-b367d541e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, perform the merge based on the 'tenor' column\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.merge(\n",
    "    curva_di[['tenor', 'bid_yield']], on='tenor', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0335ffc-2b7b-432a-8491-6ba24c61a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventos_debenture_cdi['cdi'] = eventos_debenture_cdi['cdi'].fillna(\n",
    "    eventos_debenture_cdi['bid_yield'])\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.drop(columns=['bid_yield'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176976fd-2feb-45e6-b4dc-fe616aee854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a new column for the 'end_date' by shifting 'data_evento' column up by one row\n",
    "eventos_debenture_cdi['start_date'] = eventos_debenture_cdi['data_evento'].shift(\n",
    "    1)\n",
    "eventos_debenture_cdi['end_date'] = eventos_debenture_cdi['data_evento']\n",
    "\n",
    "eventos_debenture_cdi.loc[eventos_debenture_cdi['start_date'].isnull(\n",
    "), 'start_date'] = eventos_debenture_cdi['inicio_rentabilidade']\n",
    "\n",
    "# Create a boolean Series where the current 'codigo_ticker' is different from the previous one\n",
    "codigo_change = eventos_debenture_cdi['codigo_ticker'] != eventos_debenture_cdi['codigo_ticker'].shift(\n",
    "    1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ad58c-138a-45a3-9cbe-6e9c2dbf7e00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use .loc to update 'start_date' where 'codigo_ticker' changes\n",
    "eventos_debenture_cdi.loc[codigo_change,\n",
    "                          'start_date'] = eventos_debenture_cdi['inicio_rentabilidade']\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for i in range(1, len(eventos_debenture_cdi)):  # Start from 1 to avoid accessing index -1\n",
    "    # Check if start_date is equal to end_date\n",
    "    if ((eventos_debenture_cdi.loc[i, 'start_date'] == eventos_debenture_cdi.loc[i, 'end_date']) & (eventos_debenture_cdi.loc[i, 'evento'] == 'Pagamento de juros')) or (eventos_debenture_cdi.loc[i - 1, 'evento'] == 'Premio'):\n",
    "        # Update the current row's start_date with the previous row's start_date\n",
    "        eventos_debenture_cdi.loc[i,\n",
    "                                  'start_date'] = eventos_debenture_cdi.loc[i - 1, 'start_date']\n",
    "\n",
    "# Now, apply the get_busdays function using the start_date and end_date\n",
    "eventos_debenture_cdi['dp'] = eventos_debenture_cdi.apply(\n",
    "    lambda row: get_busdays(row['start_date'], row['end_date']) if pd.notnull(\n",
    "        row['start_date']) else None,\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7ef5d-ffb2-4061-a223-2e46ac1440e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to replace 'dp' value with the previous row's value if it's 1 or 0\n",
    "\n",
    "def use_prev_dp(row, prev_dp):\n",
    "    if row['dp'] in [0, 1]:\n",
    "        return prev_dp\n",
    "    return row['dp']\n",
    "\n",
    "\n",
    "# Iterate through the DataFrame and adjust 'dp' where necessary\n",
    "prev_dp = None  # To store the previous row's dp value\n",
    "for idx in range(len(eventos_debenture_cdi)):\n",
    "    current_dp = eventos_debenture_cdi.at[idx, 'dp']\n",
    "    if pd.notnull(current_dp):  # Check if 'dp' is not null\n",
    "        new_dp = use_prev_dp(eventos_debenture_cdi.iloc[idx], prev_dp)\n",
    "        eventos_debenture_cdi.at[idx, 'dp'] = new_dp\n",
    "        prev_dp = new_dp  # Update prev_dp for the next iteration\n",
    "\n",
    "# Loop over the DataFrame using the index and iterrows()\n",
    "for i in range(1, len(eventos_debenture_cdi)):  # Start from 1 to avoid going out of bounds\n",
    "    if eventos_debenture_cdi.loc[i, 'evento'] == 'Amortizacao':\n",
    "        if eventos_debenture_cdi.loc[i, 'codigo_ticker'] == 'SNGO18':\n",
    "            # Update 'juros_pagos' for 'Amortizacao' event using the previous row 'pu'\n",
    "            eventos_debenture_cdi.loc[i, 'juros_pagos'] = (\n",
    "                eventos_debenture_cdi.loc[i - 1, 'vne'] *\n",
    "                (eventos_debenture_cdi.loc[i, 'percentual_taxa'] / 100)\n",
    "            )\n",
    "        else:\n",
    "            # Update 'juros_pagos' for 'Amortizacao' event using the previous row 'pu'\n",
    "            eventos_debenture_cdi.loc[i, 'juros_pagos'] = (\n",
    "                eventos_debenture_cdi.loc[i - 1, 'pu'] *\n",
    "                (eventos_debenture_cdi.loc[i, 'percentual_taxa'] / 100)\n",
    "            )\n",
    "    elif eventos_debenture_cdi.loc[i, 'evento'] == 'Premio':\n",
    "        eventos_debenture_cdi.loc[i,\n",
    "                                  'juros_pagos'] = eventos_debenture_cdi.loc[i, 'valor_pago']\n",
    "\n",
    "#CALCULAR EXP, EXP1, DP1\n",
    "\n",
    "# Apply the function and create the new column 'juros_pagos'\n",
    "# eventos_debenture_cdi['juros_pagos'] = eventos_debenture_cdi.apply(apply_calcular_juros, axis=1)\n",
    "# Create a mask for rows where 'juros_pagos' is null\n",
    "mask = eventos_debenture_cdi['juros_pagos'].isna()\n",
    "eventos_debenture_cdi.loc[mask, 'juros_pagos'] = eventos_debenture_cdi[mask].apply(\n",
    "    apply_calcular_juros, axis=1)\n",
    "\n",
    "# Create a dictionary mapping English month names to Portuguese\n",
    "month_mapping = {\n",
    "    'January': 'Janeiro',\n",
    "    'February': 'Fevereiro',\n",
    "    'March': 'Março',\n",
    "    'April': 'Abril',\n",
    "    'May': 'Maio',\n",
    "    'June': 'Junho',\n",
    "    'July': 'Julho',\n",
    "    'August': 'Agosto',\n",
    "    'September': 'Setembro',\n",
    "    'October': 'Outubro',\n",
    "    'November': 'Novembro',\n",
    "    'December': 'Dezembro'\n",
    "}\n",
    "\n",
    "# Extract the English month names and map them to Portuguese using the dictionary\n",
    "eventos_debenture_cdi['month_w'] = eventos_debenture_cdi['data_evento'].dt.strftime(\n",
    "    '%B').map(month_mapping)\n",
    "eventos_debenture_cdi['year_w'] = eventos_debenture_cdi['data_evento'].dt.year\n",
    "\n",
    "# sql query to read all the records\n",
    "posicoes_query = pd.read_sql(\n",
    "    'SELECT * FROM posicoes_pbi ORDER BY posicao_id', engine)\n",
    "\n",
    "# convert the SQL table into a pandas dataframe\n",
    "posicoes_pbi = pd.DataFrame(posicoes_query)\n",
    "\n",
    "grouped_df = posicoes_pbi[['data', 'codigo_custodia_ticker', 'quantidade', 'fundo']][(posicoes_pbi['tipo_papel_resumido'] == 'DEBENTURE')].groupby(['data', 'codigo_custodia_ticker', 'fundo']).agg({\n",
    "    'quantidade': 'sum'  # Use sum or any other aggregate function\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "grouped_df['data'] = pd.to_datetime(grouped_df['data'])\n",
    "\n",
    "max_date = eventos_debenture_cdi['data_evento'].max()\n",
    "min_date = grouped_df['data'].max()\n",
    "\n",
    "custom_business_day = CustomBusinessDay(calendar=CustomBusinessCalendar())\n",
    "new_dates = pd.bdate_range(\n",
    "    start=min_date, end=max_date, freq=custom_business_day)\n",
    "new_dates = new_dates[1:]\n",
    "\n",
    "new_entries = pd.DataFrame({\n",
    "    'data': new_dates,\n",
    "    'codigo_custodia_ticker': np.nan,\n",
    "    'fundo': np.nan,\n",
    "    'quantidade': [float('nan')] * len(new_dates)\n",
    "})\n",
    "\n",
    "current_entries = grouped_df[['codigo_custodia_ticker', 'fundo',\n",
    "                              'quantidade']][grouped_df['data'] == min_date].reset_index(drop=True)\n",
    "new_entries = new_entries.reset_index(drop=True)\n",
    "current_entries = current_entries.reset_index(drop=True)\n",
    "\n",
    "# Add a key column to both DataFrames for cross join\n",
    "new_entries['key'] = 1\n",
    "current_entries['key'] = 1\n",
    "\n",
    "# Perform the cross join\n",
    "new_entries = pd.merge(new_entries, current_entries,\n",
    "                       on='key').drop('key', axis=1)\n",
    "\n",
    "new_entries = new_entries.drop(\n",
    "    columns=['codigo_custodia_ticker_x', 'fundo_x', 'quantidade_x'])\n",
    "new_entries = new_entries.rename(columns={\n",
    "    'codigo_custodia_ticker_y': 'codigo_custodia_ticker',\n",
    "    'fundo_y': 'fundo',\n",
    "    'quantidade_y': 'quantidade'\n",
    "})\n",
    "\n",
    "# Append the new entries to indicador_cdi\n",
    "grouped_df = pd.concat([grouped_df, new_entries], ignore_index=True)\n",
    "\n",
    "# Sort the DataFrame by 'data' to maintain chronological order\n",
    "grouped_df.sort_values(by='data', inplace=True)\n",
    "\n",
    "# Reset index if necessary\n",
    "grouped_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge eventos_debenture_cdi with grouped_df\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.merge(\n",
    "    grouped_df,\n",
    "    # Columns from eventos_debenture_cdi\n",
    "    left_on=['data_liquidacao', 'codigo_ticker'],\n",
    "    right_on=['data', 'codigo_custodia_ticker'],  # Columns from grouped_df\n",
    "    how='left'  # Choose 'left' to keep all rows from eventos_debenture_cdi\n",
    ")\n",
    "\n",
    "# Drop unnecessary columns after merge\n",
    "eventos_debenture_cdi = eventos_debenture_cdi.drop(\n",
    "    columns=['data', 'codigo_custodia_ticker'])\n",
    "\n",
    "eventos_debenture_cdi = eventos_debenture_cdi[eventos_debenture_cdi['data_evento'] >= '01-01-2024']\n",
    "\n",
    "eventos_debenture_cdi['quantidade'] = eventos_debenture_cdi['quantidade'].fillna(\n",
    "    method='ffill')\n",
    "eventos_debenture_cdi['fundo'] = eventos_debenture_cdi['fundo'].fillna(\n",
    "    method='ffill')\n",
    "\n",
    "# Create the 'valor_recebido' column with the specified conditions\n",
    "eventos_debenture_cdi['valor_recebido'] = np.where(\n",
    "    eventos_debenture_cdi['valor_pago'].notnull(),\n",
    "    # If 'valor_pago' is not null\n",
    "    eventos_debenture_cdi['valor_pago'] * eventos_debenture_cdi['quantidade'],\n",
    "    # If 'valor_pago' is null\n",
    "    eventos_debenture_cdi['juros_pagos'] * eventos_debenture_cdi['quantidade']\n",
    ")\n",
    "\n",
    "\n",
    "eventos_debenture_cdi.reset_index(drop=True, inplace=True)\n",
    "eventos_debenture_cdi['deb_id'] = eventos_debenture_cdi.index\n",
    "\n",
    "# Iterate over rows and apply the function\n",
    "for i in range(1, len(eventos_debenture_cdi)):\n",
    "    eventos_debenture_cdi.at[i, 'valor_recebido'] = update_valor_recebido(\n",
    "        eventos_debenture_cdi.iloc[i], eventos_debenture_cdi.iloc[i - 1]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e44f9-d12c-4f98-83a5-b0cfd68fbf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eventos_debenture_cdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c42e0d-4053-4a66-82e9-b730f6a189b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7398018-328a-4966-9751-74086659103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(eventos_debenture_cdi['codigo_ticker'][eventos_debenture_cdi['inicio_rentabilidade'] >= '2023-01-01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae2715-c9ba-43cd-80fb-bcd4e7d66f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eventos_debenture_cdi[eventos_debenture_cdi['codigo_ticker'] == 'BSA317']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b59fd4-0958-4976-9e6b-624829b2eaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: 'postgresql://username:password@localhost:5432/your_database'\n",
    "engine = create_engine(\n",
    "    'postgresql://postgres:admin@192.168.88.61:5432/posicoesdb')\n",
    "\n",
    "# Initialize metadata object\n",
    "metadata = MetaData()\n",
    "\n",
    "# Load a table from the database using its name\n",
    "table_eventos_debenture_cdi = Table(\n",
    "    'cp_eventos_debenture_di', metadata, autoload_with=engine)\n",
    "\n",
    "# Drop the table\n",
    "table_eventos_debenture_cdi.drop(engine)\n",
    "\n",
    "# Create the table\n",
    "table_eventos_debenture_cdi.create(engine)\n",
    "\n",
    "start_time = time.time()  # get start time before insert\n",
    "\n",
    "eventos_debenture_cdi.set_index('deb_id', inplace=True)\n",
    "\n",
    "# Subir deb no bd\n",
    "eventos_debenture_cdi.to_sql(\n",
    "    name=\"cp_eventos_debenture_di\",  # table name\n",
    "    con=engine,  # engine\n",
    "    if_exists=\"append\",  # If the table already exists, append\n",
    "    index=True  # no index\n",
    ")\n",
    "\n",
    "end_time = time.time()  # get end time after insert\n",
    "total_time = end_time - start_time  # calculate the time\n",
    "print(f\"Insert time: {total_time} seconds\")  # print time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df4788-a7a0-4651-9c1d-cb101af3cc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06825059-4290-499c-b17f-8ec5e12ac6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
